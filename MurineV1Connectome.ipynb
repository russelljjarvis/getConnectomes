{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Allen V1 connectome\n",
    "### With minimal dependencies\n",
    "\n",
    "SONATA, reads and writes hdf5 files.\n",
    "\n",
    "## Step 1\n",
    "Download [this whole drop box directory](https://www.dropbox.com/sh/w5u31m3hq6u2x5m/AABGlA4w3k72vWmNndkyDbxZa/GLIF%20Network/network?dl=0&subfolder_nav_tracking=1). \n",
    "If you can find the wget syntax for this, I would be greatful for that.\n",
    "Place the contents of that directory, in the same directory as this notebook.\n",
    "## Step 2\n",
    "Pip install sonata and hdf5, as I am going to assume you don't already have those packages.\n",
    "## Step 3. \n",
    "* Arguably the data is already in it's ideal format for reading and writing graphs (big data/hdf5 no brainer).\n",
    "\n",
    "* We are going to move the needle backwards, and transform the network into networkx, this will facilitate a transformation to Julia JLD files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5dict\n",
    "from sonata.circuit import File\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading SONATA Network files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "netv1 = File(data_files=['v1_nodes.h5', \n",
    "                       'v1_v1_edges.h5',\n",
    "                       'lgn_v1_edges.h5',\n",
    "                       'bkg_v1_edges.h5',\n",
    "                       'lgn_nodes.h5',\n",
    "                       'bkg_nodes.h5',\n",
    "                      ], \n",
    "           data_type_files=['v1_node_types.csv',\n",
    "                            'v1_v1_edge_types.csv',\n",
    "                            'bkg_node_types.csv',\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge populations in file: ['v1_to_v1', 'lgn_to_v1', 'bkg_to_v1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|â–Ž                                                                     | 270810/70139111 [00:06<25:42, 45292.83it/s]"
     ]
    }
   ],
   "source": [
    "v1_edges = netv1.edges\n",
    "print('Edge populations in file: {}'.format(v1_edges.population_names))\n",
    "for key in v1_edges.population_names:\n",
    "    exec(\"g\"+str(key)+str(\" = nx.Graph()\"))\n",
    "    exec(\"this_name=\"+str(\"g\")+str(key))\n",
    "    temp = {}\n",
    "    for edge in tqdm.tqdm(netv1.edges[key]):        \n",
    "        if hasattr(edge,\"plastic\"):\n",
    "            temp[\"plastic\"] = True\n",
    "        else:\n",
    "            temp[\"plastic\"] = False \n",
    "        if hasattr(edge,\"delay\"):\n",
    "            temp[\"delay\"] = edge.delay\n",
    "        else:\n",
    "            temp[\"delay\"] = False\n",
    "\n",
    "        if hasattr(edge,\"nsyns\"):\n",
    "            temp[\"nsyns\"] = edge.nsyns\n",
    "        else:\n",
    "            temp[\"nsyns\"] = 1.0\n",
    "        if hasattr(edge,\"syn_weight\"): \n",
    "            this_name.add_edge(str(edge.source_node_id),str(edge.target_node_id),weight=edge.syn_weight)        \n",
    "        else:\n",
    "            this_name.add_edge(str(edge.source_node_id),str(edge.target_node_id),weight=0.0)\n",
    "        for k,v in temp.items():\n",
    "            this_name.edges[str(edge.source_node_id),str(edge.target_node_id)][k] = v \n",
    "    v1_v1_dict = h5dict.File(str(\"AllenV1Murine2\")+str(key)+str(\".hdf5\"), \"w\") \n",
    "    filters = {\"compression\": \"lzf\"}\n",
    "    v1_v1_dict[\"network\",filters] = v1_v1_dict\n",
    "    #v1_v1_dict[\"network\"] = v1_v1_dict\n",
    "    v1_v1_dict.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = h5dict.File(str(\"AllenV1Murine2\")+str(key)+str(\".hdf5\"), \"r+\")    \n",
    "test_dict\n",
    "test_dict.tree_view(print_types=True)\n",
    "G = test_dict[\"network\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
